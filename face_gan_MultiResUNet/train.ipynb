{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import Dataset\n",
    "from torch.utils.data import DataLoader\n",
    "import pytorch_lightning as pl\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision import transforms\n",
    "import itertools\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "import os\n",
    "import yaml\n",
    "import random\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "IMG_EXTENSIONS = [\"png\", \"jpg\"]\n",
    "\n",
    "class ImagetoImageDataset(Dataset):\n",
    "    def __init__(self, domainA_dir, domainB_dir, transforms=None):\n",
    "        self.imagesA = [os.path.join(domainA_dir, x) for x in os.listdir(domainA_dir) if\n",
    "                        x.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
    "        self.imagesB = [os.path.join(domainB_dir, x) for x in os.listdir(domainB_dir) if\n",
    "                        x.lower().endswith(tuple(IMG_EXTENSIONS))]\n",
    "\n",
    "        self.transforms = transforms\n",
    "\n",
    "        self.lenA = len(self.imagesA)\n",
    "        self.lenB = len(self.imagesB)\n",
    "\n",
    "    def __len__(self):\n",
    "        return max(self.lenA, self.lenB)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        idx_a = idx_b = idx\n",
    "        if idx_a >= self.lenA:\n",
    "            idx_a = np.random.randint(self.lenA)\n",
    "        if idx_b >= self.lenB:\n",
    "            idx_b = np.random.randint(self.lenB)\n",
    "        \n",
    "        imageA = np.array(Image.open(self.imagesA[idx_a]).convert(\"RGB\"))\n",
    "        imageB = np.array(Image.open(self.imagesB[idx_b]).convert(\"RGB\"))\n",
    "\n",
    "        if self.transforms is not None:\n",
    "            imageA = self.transforms(imageA)\n",
    "            imageB = self.transforms(imageB)\n",
    "\n",
    "        return imageA, imageB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ConvBlock2d(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, kernel_size, stride=(1, 1), activation='relu'):\n",
    "        super(ConvBlock2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_feature, out_feature, kernel_size=kernel_size, stride=stride, padding='same')\n",
    "        # self.batchNorm = nn.BatchNorm2d(out_feature)\n",
    "        self.activation = activation\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # x = self.batchNorm(self.conv(x))\n",
    "        x = self.conv(x)\n",
    "        if self.activation == 'relu':\n",
    "            return F.relu(x)\n",
    "        else:\n",
    "            return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiResBlock(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature):\n",
    "        super(MultiResBlock, self).__init__()\n",
    "        feature_3x3 = out_feature // 6\n",
    "        feature_5x5 = out_feature // 3\n",
    "        feature_7x7 = out_feature - feature_3x3 - feature_5x5\n",
    "        self.conv_3x3 = ConvBlock2d(in_feature, feature_3x3, kernel_size=3)\n",
    "        self.conv_5x5 = ConvBlock2d(feature_3x3, feature_5x5, kernel_size=3)\n",
    "        self.conv_7x7 = ConvBlock2d(feature_5x5, feature_7x7, kernel_size=3)\n",
    "\n",
    "        self.conv_1x1 = ConvBlock2d(in_feature, out_feature, kernel_size=1)\n",
    "\n",
    "        # self.batch_norm1 = nn.BatchNorm2d(out_feature)\n",
    "        # self.batch_norm2 = nn.BatchNorm2d(out_feature)\n",
    "\n",
    "    def forward(self, x):\n",
    "        o_3x3 = self.conv_3x3(x)\n",
    "        o_5x5 = self.conv_5x5(o_3x3)\n",
    "        o_7x7 = self.conv_7x7(o_5x5)\n",
    "        # o = self.batch_norm1(torch.cat([o_3x3, o_5x5, o_7x7], axis=1))\n",
    "        o = torch.cat([o_3x3, o_5x5, o_7x7], axis=1)\n",
    "\n",
    "        o_1x1 = self.conv_1x1(x)\n",
    "\n",
    "        # o = self.batch_norm1(o + o_1x1)\n",
    "        o = o + o_1x1\n",
    "\n",
    "        return F.relu(o)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResPath(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, length):\n",
    "        super(ResPath, self).__init__()\n",
    "        self.respath_length = length\n",
    "        self.residuals = torch.nn.ModuleList([])\n",
    "        self.convs = torch.nn.ModuleList([])\n",
    "        # self.bns = torch.nn.ModuleList([])\n",
    "\n",
    "        for i in range(self.respath_length):\n",
    "            if(i==0):\n",
    "                self.residuals.append(ConvBlock2d(in_feature, out_feature, kernel_size = (1,1), activation='None'))\n",
    "                self.convs.append(ConvBlock2d(in_feature, out_feature, kernel_size = (3,3),activation='relu'))\n",
    "\n",
    "            \t\n",
    "            else:\n",
    "                self.residuals.append(ConvBlock2d(out_feature, out_feature, kernel_size = (1,1), activation='None'))\n",
    "                self.convs.append(ConvBlock2d(out_feature, out_feature, kernel_size = (3,3), activation='relu'))\n",
    "\n",
    "            # self.bns.append(torch.nn.BatchNorm2d(out_feature))\n",
    "\n",
    "    def forward(self, x):\n",
    "        \n",
    "        for i in range(self.respath_length):\n",
    "            res = self.residuals[i](x)\n",
    "\n",
    "            x = self.convs[i](x)\n",
    "            # x = self.bns[i](x)\n",
    "            # x = torch.nn.functional.relu(x)\n",
    "\n",
    "            x = x + res\n",
    "            # x = self.bns[i](x)\n",
    "            x = torch.nn.functional.relu(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MultiResUNet(nn.Module):\n",
    "    def __init__(self, in_feature, out_feature, alpha=1.667, ngf = 32):\n",
    "        super(MultiResUNet, self).__init__()\n",
    "        #encoder\n",
    "        feature1 = int(ngf * alpha)\n",
    "        self.multi1 = MultiResBlock(in_feature, feature1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "        self.respath1 = ResPath(feature1, ngf, length=4)\n",
    "\n",
    "        feature2 = int(ngf * 2 * alpha)\n",
    "        self.multi2 = MultiResBlock(feature1, feature2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "        self.respath2 = ResPath(feature2, ngf * 2, length=3)\n",
    "\n",
    "        feature3 = int(ngf * 4 * alpha)\n",
    "        self.multi3 = MultiResBlock(feature2, feature3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "        self.respath3 = ResPath(feature3, ngf * 4, length=2)\n",
    "\n",
    "        feature4 = int(ngf * 8 * alpha)\n",
    "        self.multi4 = MultiResBlock(feature3, feature4)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "        self.respath4 = ResPath(feature4, ngf * 8, length=1)\n",
    "\n",
    "        feature5 = int(ngf * 16 * alpha)\n",
    "        self.multi5 = MultiResBlock(feature4, feature5)\n",
    "\n",
    "        #decoder\n",
    "        out_feature5 = feature5\n",
    "        self.upsample1 = nn.ConvTranspose2d(out_feature5, ngf * 8, kernel_size = (2, 2), stride = (2, 2))  \n",
    "        out_feature4 = int(ngf * 8 * alpha)\n",
    "        self.multi6 = MultiResBlock(ngf * 8 * 2, out_feature4)\n",
    "        \n",
    "        self.upsample2 = nn.ConvTranspose2d(out_feature4, ngf * 4, kernel_size = (2, 2), stride = (2, 2))\n",
    "        out_feature3 = int(ngf * 4 * alpha)  \n",
    "        self.multi7 = MultiResBlock(ngf * 4 * 2, out_feature3)\n",
    "\t\n",
    "        self.upsample3 = nn.ConvTranspose2d(out_feature3, ngf * 2, kernel_size = (2, 2), stride = (2, 2))\n",
    "        out_feature2 = int(ngf * 2 * alpha)\n",
    "        self.multi8 = MultiResBlock(ngf * 2 * 2, out_feature2)\n",
    "\t\t\n",
    "        self.upsample4 = nn.ConvTranspose2d(out_feature2, ngf, kernel_size = (2, 2), stride = (2, 2))\n",
    "        out_feature1 = int(ngf * alpha)\n",
    "        self.multi9 = MultiResBlock(ngf * 2, out_feature1)\n",
    "\n",
    "        self.conv_final = ConvBlock2d(out_feature1, out_feature, kernel_size = (1,1), activation='None')\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoder\n",
    "        layer1 = self.multi1(x)        \n",
    "        layer2 = self.multi2(self.pool1(layer1))\n",
    "        layer3 = self.multi3(self.pool2(layer2))\n",
    "        layer4 = self.multi4(self.pool3(layer3))\n",
    "        layer5 = self.multi5(self.pool4(layer4))\n",
    "        #decoder\n",
    "        layer4 = self.multi6(torch.cat([self.upsample1(layer5), self.respath4(layer4)], axis=1))\n",
    "        layer3 = self.multi7(torch.cat([self.upsample2(layer4), self.respath3(layer3)], axis=1))\n",
    "        layer2 = self.multi8(torch.cat([self.upsample3(layer3), self.respath2(layer2)], axis=1))\n",
    "        layer1 = self.multi9(torch.cat([self.upsample4(layer2), self.respath1(layer1)], axis=1))\n",
    "\n",
    "        return self.conv_final(layer1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Discriminator(nn.Module):\n",
    "    def __init__(self, in_feature, alpha=0.667, ndf = 32):\n",
    "        super(Discriminator, self).__init__()\n",
    "        feature1 = int(ndf * alpha)\n",
    "        self.multi1 = MultiResBlock(in_feature, feature1)\n",
    "        self.pool1 = nn.MaxPool2d(2)\n",
    "\n",
    "        feature2 = int(ndf * 2 * alpha)\n",
    "        self.multi2 = MultiResBlock(feature1, feature2)\n",
    "        self.pool2 = nn.MaxPool2d(2)\n",
    "\n",
    "        feature3 = int(ndf * 4 * alpha)\n",
    "        self.multi3 = MultiResBlock(feature2, feature3)\n",
    "        self.pool3 = nn.MaxPool2d(2)\n",
    "\n",
    "        feature4 = int(ndf * 8 * alpha)\n",
    "        self.multi4 = MultiResBlock(feature3, feature4)\n",
    "        self.pool4 = nn.MaxPool2d(2)\n",
    "\n",
    "        feature5 = int(ndf * 16 * alpha)\n",
    "        self.multi5 = MultiResBlock(feature4, feature5)\n",
    "        self.pool5 = nn.MaxPool2d(2)\n",
    "\n",
    "        self.FC = nn.Linear(feature5 * 8 * 8, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        #encoder\n",
    "        layer = self.multi1(x)        \n",
    "        layer = self.multi2(self.pool1(layer))\n",
    "        layer = self.multi3(self.pool2(layer))\n",
    "        layer = self.multi4(self.pool3(layer))\n",
    "        layer = self.multi5(self.pool4(layer))\n",
    "        layer = self.FC(self.pool5(layer).view(x.shape[0], -1))\n",
    "        return F.sigmoid(layer)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "@torch.no_grad()\n",
    "def infer():\n",
    "    args = {\n",
    "        'config': 'configs/aging_gan.yaml',\n",
    "        'checkpoint_dir': './pretrained/',\n",
    "        'image_dir': './archive/test_image/'\n",
    "    }\n",
    "    with open(args['config']) as file:\n",
    "        configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    image_dir_O = args['image_dir'] + 'testO/'\n",
    "    image_dir_Y = args['image_dir'] + 'testY/'\n",
    "    old_image_paths = [os.path.join(image_dir_O, x) for x in os.listdir(image_dir_O) if\n",
    "                   x.endswith('.png') or x.endswith('.jpg')]\n",
    "    young_image_paths = [os.path.join(image_dir_Y, x) for x in os.listdir(image_dir_Y) if\n",
    "                   x.endswith('.png') or x.endswith('.jpg')]\n",
    "    \n",
    "    model = MultiResUNet(3, 3, configs['gen_alpha'], configs['ngf'])\n",
    "    ckpt = torch.load(args['checkpoint_dir'] + configs['y2o'], map_location='cpu')\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    nr_images = len(young_image_paths) \n",
    "    fig, ax = plt.subplots(2, nr_images, figsize=(20, 10))\n",
    "    random.shuffle(young_image_paths)\n",
    "    for i in range(nr_images):\n",
    "        img = Image.open(young_image_paths[i]).convert('RGB')\n",
    "        img = trans(img).unsqueeze(0)\n",
    "        aged_face = model(img)\n",
    "        aged_face = (aged_face.squeeze().permute(1, 2, 0).numpy() + 1.0) / 2.0\n",
    "        ax[0, i].imshow((img.squeeze().permute(1, 2, 0).numpy() + 1.0) / 2.0)\n",
    "        ax[1, i].imshow(aged_face)\n",
    "    plt.show()\n",
    "    plt.savefig(\"mygraph_y2o.png\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "    model = MultiResUNet(3, 3, configs['gen_alpha'], configs['ngf'])\n",
    "    ckpt = torch.load(args['checkpoint_dir'] + configs['o2y'], map_location='cpu')\n",
    "    model.load_state_dict(ckpt)\n",
    "    model.eval()\n",
    "    trans = transforms.Compose([\n",
    "        transforms.Resize((512, 512)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "    ])\n",
    "    nr_images = len(old_image_paths) \n",
    "    fig, ax = plt.subplots(2, nr_images, figsize=(20, 10))\n",
    "    random.shuffle(old_image_paths)\n",
    "    for i in range(nr_images):\n",
    "        img = Image.open(old_image_paths[i]).convert('RGB')\n",
    "        img = trans(img).unsqueeze(0)\n",
    "        aged_face = model(img)\n",
    "        aged_face = (aged_face.squeeze().permute(1, 2, 0).numpy() + 1.0) / 2.0\n",
    "        ax[0, i].imshow((img.squeeze().permute(1, 2, 0).numpy() + 1.0) / 2.0)\n",
    "        ax[1, i].imshow(aged_face)\n",
    "    plt.show()\n",
    "    plt.savefig(\"mygraph_o2y.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GAN(pl.LightningModule):\n",
    "    def load_from_checkpoint(self, checkpoint_path):\n",
    "        y2o = checkpoint_path + self.hparams['y2o']\n",
    "        o2y = checkpoint_path + self.hparams['o2y']\n",
    "        self.genY2O.load_state_dict(torch.load(y2o))\n",
    "        self.genO2Y.load_state_dict(torch.load(o2y))\n",
    "\n",
    "    def __init__(self, hparams):\n",
    "        super(GAN, self).__init__()\n",
    "        self.automatic_optimization = False\n",
    "        self.save_hyperparameters(hparams)\n",
    "        self.genY2O = MultiResUNet(3, 3, self.hparams['gen_alpha'], self.hparams['ngf'])\n",
    "        self.genO2Y = MultiResUNet(3, 3, self.hparams['gen_alpha'], self.hparams['ngf'])\n",
    "        self.disY = Discriminator(3, self.hparams['dis_alpha'], self.hparams['ndf'])\n",
    "        self.disO = Discriminator(3, self.hparams['dis_alpha'], self.hparams['ndf'])\n",
    "\n",
    "        # cache for generated images\n",
    "        self.generated_Y = None\n",
    "        self.generated_O = None\n",
    "        self.real_Y = None\n",
    "        self.real_O = None\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.genY2O(x)\n",
    "    \n",
    "    def training_step(self, batch, batch_idx):\n",
    "        g_optim, d_optim = self.optimizers()\n",
    "        g_optim.zero_grad()\n",
    "        \n",
    "        self.disO.requires_grad_(False)\n",
    "        self.disY.requires_grad_(False)\n",
    "        real_Y, real_O = batch\n",
    "\n",
    "\n",
    "        fake_O = self.genY2O(real_Y)\n",
    "        pred_O = self.disO(fake_O)\n",
    "        loss_Y2O = F.binary_cross_entropy(pred_O, torch.ones(pred_O.shape).type_as(pred_O))\n",
    "\n",
    "        rec_Y = self.genO2Y(fake_O)\n",
    "        loss_Y2O2Y = F.mse_loss(rec_Y, real_Y)\n",
    "\n",
    "        real_GY = self.genO2Y(real_Y)\n",
    "        loss_Y2Y = F.mse_loss(real_GY, real_Y)\n",
    "\n",
    "\n",
    "\n",
    "        fake_Y = self.genO2Y(real_Y)\n",
    "        pred_Y = self.disY(fake_Y)\n",
    "        loss_O2Y = F.binary_cross_entropy(pred_Y, torch.ones(pred_Y.shape).type_as(pred_Y))\n",
    "\n",
    "        rec_O = self.genY2O(fake_Y)\n",
    "        loss_O2Y2O = F.mse_loss(rec_O, real_O)\n",
    "\n",
    "        real_GO = self.genY2O(real_O)\n",
    "        loss_O2O = F.mse_loss(real_GO, real_O)\n",
    "        \n",
    "\n",
    "        g_loss = (loss_Y2O + loss_O2Y) * self.hparams['adv_weight'] + (loss_Y2Y + loss_O2O) * self.hparams['identity_weight'] + (loss_Y2O2Y + loss_O2Y2O) * self.hparams['cycle_weight']\n",
    "\n",
    "\n",
    "        \n",
    "\n",
    "        # Log to tb\n",
    "        if batch_idx % 500 == 0:\n",
    "            self.genY2O.eval()\n",
    "            self.genY2O.eval()\n",
    "            fake_Y = self.genO2Y(real_O)\n",
    "            fake_O = self.genY2O(real_Y)\n",
    "            self.logger.experiment.add_image('Real/Y', make_grid(real_Y, normalize=True, scale_each=True),\n",
    "                                                self.current_epoch)\n",
    "            self.logger.experiment.add_image('Real/O', make_grid(real_O, normalize=True, scale_each=True),\n",
    "                                                self.current_epoch)\n",
    "            self.logger.experiment.add_image('Generated/Y',\n",
    "                                                make_grid(fake_Y, normalize=True, scale_each=True),\n",
    "                                                self.current_epoch)\n",
    "            self.logger.experiment.add_image('Generated/O',\n",
    "                                                make_grid(fake_O, normalize=True, scale_each=True),\n",
    "                                                self.current_epoch)\n",
    "            self.genY2O.train()\n",
    "            self.genO2Y.train()\n",
    "\n",
    "            output_path = './pretrained/'\n",
    "            torch.save(self.genY2O.state_dict(), f\"{output_path}{self.hparams['y2o']}\")\n",
    "            torch.save(self.genO2Y.state_dict(), f\"{output_path}{self.hparams['o2y']}\")\n",
    "\n",
    "            infer()\n",
    "\n",
    "        self.manual_backward(g_loss)\n",
    "        g_optim.step()\n",
    "        self.disO.requires_grad_(True)\n",
    "        self.disY.requires_grad_(True)\n",
    "\n",
    "        self.log('Loss/Generator', g_loss.detach())\n",
    "\n",
    "        d_optim.zero_grad()\n",
    "        self.genO2Y.requires_grad_(False)\n",
    "        self.genY2O.requires_grad_(False)\n",
    "\n",
    "        pred_RY = self.disY(real_Y)\n",
    "        loss_RY = F.binary_cross_entropy(pred_RY, torch.ones(pred_RY.shape).type_as(pred_RY))\n",
    "\n",
    "        pred_RO = self.disY(real_O)\n",
    "        loss_RO = F.binary_cross_entropy(pred_RO, torch.ones(pred_RO.shape).type_as(pred_RO))\n",
    "\n",
    "        pred_FY = self.disY(self.genO2Y(real_O))\n",
    "        loss_FY = F.binary_cross_entropy(pred_FY, torch.zeros(pred_FY.shape).type_as(pred_FY))\n",
    "\n",
    "        pred_FO = self.disO(self.genY2O(real_Y))\n",
    "        loss_FO = F.binary_cross_entropy(pred_FO, torch.zeros(pred_FO.shape).type_as(pred_FO))\n",
    "\n",
    "        d_loss = loss_RO + loss_FO + loss_RY + loss_FY\n",
    "\n",
    "\n",
    "        self.manual_backward(d_loss)\n",
    "        d_optim.step()\n",
    "        self.genO2Y.requires_grad_(True)\n",
    "        self.genY2O.requires_grad_(True)\n",
    "\n",
    "        self.log('Loss/Discriminator', d_loss.detach())\n",
    "        \n",
    "\n",
    "        \n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        g_optim = torch.optim.Adam(itertools.chain(self.genY2O.parameters(), self.genO2Y.parameters()),\n",
    "                                   lr=self.hparams['lr'], betas=(0.5, 0.999),\n",
    "                                   weight_decay=self.hparams['weight_decay'])\n",
    "        d_optim = torch.optim.Adam(itertools.chain(self.disY.parameters(),\n",
    "                                                   self.disO.parameters()),\n",
    "                                   lr=self.hparams['lr'],\n",
    "                                   betas=(0.5, 0.999),\n",
    "                                   weight_decay=self.hparams['weight_decay'])\n",
    "        return [g_optim, d_optim], []\n",
    "    \n",
    "\n",
    "    def train_dataloader(self):\n",
    "        train_transform = transforms.Compose([\n",
    "            transforms.ToPILImage(),\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.Resize((self.hparams['img_size'] + 50, self.hparams['img_size'] + 50)),\n",
    "            transforms.RandomCrop(self.hparams['img_size']),\n",
    "            #transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3),\n",
    "            #transforms.RandomPerspective(p=0.5),\n",
    "            transforms.RandomRotation(degrees=(0, int(self.hparams['augment_rotation']))),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))\n",
    "        ])\n",
    "        dataset = ImagetoImageDataset(self.hparams['domainY_dir'], self.hparams['domainO_dir'], train_transform)\n",
    "        #use small data\n",
    "        print(f\"Using {len(dataset)} images for training\")\n",
    "        # dataset = torch.utils.data.Subset(dataset, range(0, 10))\n",
    "\n",
    "        return DataLoader(dataset,\n",
    "                          batch_size=self.hparams['batch_size'],\n",
    "                          num_workers=self.hparams['num_workers'],\n",
    "                          shuffle=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train():\n",
    "    args = {\n",
    "        'config': 'configs/aging_gan.yaml',\n",
    "        'load_checkpoint_dir': None,\n",
    "        'save_checkpoint_dir': None\n",
    "    }\n",
    "    with open(args['config']) as file:\n",
    "        configs = yaml.load(file, Loader=yaml.FullLoader)\n",
    "    configs['device'] = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "    torch.set_float32_matmul_precision('medium')\n",
    "    print(configs)\n",
    "    model = GAN(configs)\n",
    "    if args['load_checkpoint_dir']:\n",
    "        model.load_checkpoint(args['load_checkpoint_dir'])\n",
    "\n",
    "    trainer = Trainer(max_epochs=configs['epochs'])\n",
    "    trainer.fit(model)\n",
    "\n",
    "    output_path = args['save_checkpoint_dir'] if args['save_checkpoint_dir'] else 'pretrained/'\n",
    "    try:\n",
    "        os.mkdir(output_path)\n",
    "    except:\n",
    "        pass\n",
    "    torch.save(model.genY2O.state_dict(), f\"{output_path}{configs['y2o']}\")\n",
    "    torch.save(model.genO2Y.state_dict(), f\"{output_path}{configs['o2y']}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train()\n",
    "infer()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
